---
question: Какие методы машинного обучения, рассмотренные на лекциях, позволяют анализировать полученные решения (условный white-box), а какие - нет (условный black-box).
module: Практика
---

**Анализируемые, "прозрачные" модели (white-box)** - это модели, внутреннее устройство и параметры которых понятны человеку, и по ним можно объяснить предсказания. К таким относятся, например, **линейная регрессия и логистическая регрессия**: их коэффициенты при признаках можно интерпретировать как влияние каждого признака на результат (при прочих равных). Если признак имеет большой положительный вес - он сильно увеличивает вероятность положительного класса (в случае логистической) или повышает целевое значение (в линейной). Ещё пример - **дерево решений**: его можно изобразить как набор правил (if-then), проходя по которым, модель делает прогноз. Такое дерево легко "прочитать" - понятно, на основе какого признака и где модель разделяет данные, можно проследить путь для конкретного примера и увидеть, почему именно такой класс присвоен (например: "Если возраст > 50 и доход &lt; 30k, то… =&gt; класс A"). Таким образом, линейные модели и деревья - типичные white-box: они позволяют узнать, **почему** модель приняла решение.

**Неинтерпретируемые модели (black-box)** - это модели, у которых сложная, нелинейная структура и множество параметров, и они не дают простого объяснения своих предсказаний. К ним относятся, например, **нейронные сети** с их многослойными связями: веса нейросети трудны для прямой интерпретации человеком (их тысячи или миллионы, взаимодействия сложные). **Сложные ансамбли, как Random Forest или градиентный бустинг**, тоже выступают как чёрный ящик: хотя каждый отдельный дерево простое, сотни разных деревьев вместе уже сложно расшифровать - влияние каждого признака распределено по множеству моделей. **SVM с нелинейным ядром** - ещё один пример black-box: хоть модель и имеет математическую формулу, понять в человеческих терминах, почему данный объект отнесён к классу, сложно (она смотрит на множество опорных векторов в высокомерном пространстве). В итоге, black-box модели могут давать высокую точность, но они не объясняют своих решений "на пальцах". Поэтому их и называют чёрным ящиком - мы видим только вход и результат, а логика внутри неясна.
