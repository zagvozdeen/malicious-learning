---
question: В чем отличие задачи обнаружения выбросов (outlier detection) и обнаружение новизны (novelty detection) в контексте задачи поиска аномалий?
module: Теория
---

Различие между <strong>outlier detection</strong> и <strong>novelty detection</strong> заключается в том, имеются ли аномальные объекты в обучающей выборке и как мы к ним подходим:<br><ul><br>  <li><strong>Обнаружение выбросов (outlier detection):</strong> предполагает, что в доступных данных (в том числе обучающих) могут присутствовать выбросы – то есть точки, выбивающиеся из общего распределения. Алгоритм пытается найти необычные объекты в этом же наборе, который ему дан. По сути, это полностью непросупервайзед (безметочный) подход: модель строит представление о структуре данных и помечает те точки, которые не вписываются. Примеры: Local Outlier Factor, Isolation Forest могут использоваться так, чтобы сразу выявлять выбросы в обучающем множестве.</li><br>  <li><strong>Обнаружение новизны (novelty detection):</strong> означает, что обучающую выборку мы считаем чистой, содержащей только нормальные данные (без аномалий). Модель учится описывать "нормальное" поведение. А уже затем новые поступающие объекты проверяются на принадлежность к этому нормальному распределению – и если не принадлежат, считаются аномалиями (новыми, ранее не виданными образцами). То есть обучение и поиск аномалий разделены по времени: сначала на нормальных данных, потом проверка новых. Пример: One-Class SVM обычно тренируется на нормальных объектах и потом выявляет новизну в тестовых.</li><br></ul><br>Таким образом, разница в наличии аномалий при обучении: outlier detection – мы сразу выявляем странные точки внутри данного набора, novelty detection – мы готовим модель на хорошем наборе и ищем аномальные случаи только в будущем потоке данных.
