---
question: В чем разница между использованием деревьев решений в задачах классификации и регрессии?
module: Теория
---

Деревья решений могут применяться и для классификации, и для регрессии, но их поведение отличается:

- **Дерево классификации:** на каждом узле выбирается признак и порог (или категория), которые лучше всего разделяют данные по классам. Критерий качества разделения – снижение перемешанности классов (например, прирост информации или уменьшение impurity: энтропии или Gini). Листья дерева содержат определенный класс (или распределение вероятностей по классам, но конечный прогноз обычно самый частый класс в листе). То есть, проходя по условиям, в итоге мы определяем, к какому классу относится объект.

- **Дерево регрессии:** здесь узел делится так, чтобы минимизировать разброс численных значений целевой переменной в дочерних узлах. Часто используют критерий минимизации суммы квадратов ошибок (MSE) или дисперсии. В листе вместо класса хранится некоторое числовое значение – обычно среднее всех ответов обучающих объектов, попавших в этот лист. Предсказание для нового объекта – это среднее значение в листе, куда он попадает. Иными словами, дерево пытается разделять данные на области, внутри которых целевая переменная примерно постоянна, и предсказывает эту постоянную.

В итоге: различие в критериях обучения (классификация – стремится к чистоте по классам, регрессия – к гомогенности численных значений) и в типе предсказания (класс vs число).
