---
question: Опишите стратегии подбора оптимальных гиперпараметров моделей машинного обучения
module: Теория
---

Чтобы найти лучшие гиперпараметры модели, используют разные стратегии поиска:<br><ul><br>  <li><strong>Grid Search (полный перебор):</strong> задаётся набор возможных значений для каждого гиперпараметра и затем перебираются все комбинации в сетке. Для каждой комбинации модель обучается (обычно с перекрёстной проверкой), и выбирается комбинация с наилучшей метрикой. Этот метод прост, но при большом числе параметров и значений становится очень затратным.</li><br>  <li><strong>Random Search:</strong> вместо полного перебора, пробуют случайные комбинации гиперпараметров в заданных диапазонах. Исследования показали, что случайный поиск может быстрее найти хорошее решение, т.к. не тратит время на заведомо слабые комбинации равномерно. Мы заранее выбираем число итераций, и случайным образом выбираем значение каждого гиперпараметра по распределению. В итоге, за то же время можно покрыть больше разнообразных вариантов, чем сеткой.</li><br>  <li><strong>Байесовская оптимизация:</strong> более умный подход. Строится модель (например, гауссовский процесс) зависимости качества от гиперпараметров по уже проверенным точкам, и новые комбинации выбираются не случайно, а там, где по прогнозу может быть лучшее качество (с учётом неопределённости). Алгоритмы типа Tree-structured Parzen Estimator (TPE), используемые в Hyperopt, Optuna, или GaussianProcess (в scikit-optimize), постепенно приближаются к оптимуму с меньшим числом запусков модели.</li><br>  <li><strong>Эволюционные и другие методы:</strong> существуют и генетические алгоритмы для подбора параметров, и метод Hyperband (комбинация случайного поиска с адаптивным выделением ресурсов, когда негодные варианты отбрасываются раньше). Эти подходы пытаются более эффективно исследовать пространство параметров, особенно если параметры много и функция оценки шумная.</li><br>  <li><strong>Настройка с экспертом и поэтапно:</strong> иногда гиперпараметры подбирают вручную, используя знание алгоритма. Например, сначала настроить самый важный параметр, потом подстроить второстепенные. Или комбинировать: провести грубый поиск по широкому диапазону (random), затем сделать более мелкую сетку вокруг лучших областей. В любом случае, используют перекрёстную валидацию или выделенную валидацию, чтобы оценить качество каждой комбинации честно.</li><br></ul><br>Стратегии часто комбинируют: например, начать с random search, а затем Bayesian на лучшем интервале. Главное – автоматизировать поиск, чтобы не настраивать всё вручную, и избежать подборки под тестовую выборку (всегда держать независимый тест для финальной проверки).
