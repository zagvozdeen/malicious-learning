---
question: Опишите стратегии подбора оптимальных гиперпараметров моделей машинного обучения
module: Теория
---

Чтобы найти лучшие гиперпараметры модели, используют разные стратегии поиска:

- **Grid Search (полный перебор):** задаётся набор возможных значений для каждого гиперпараметра и затем перебираются все комбинации в сетке. Для каждой комбинации модель обучается (обычно с перекрёстной проверкой), и выбирается комбинация с наилучшей метрикой. Этот метод прост, но при большом числе параметров и значений становится очень затратным.

- **Random Search:** вместо полного перебора, пробуют случайные комбинации гиперпараметров в заданных диапазонах. Исследования показали, что случайный поиск может быстрее найти хорошее решение, т.к. не тратит время на заведомо слабые комбинации равномерно. Мы заранее выбираем число итераций, и случайным образом выбираем значение каждого гиперпараметра по распределению. В итоге, за то же время можно покрыть больше разнообразных вариантов, чем сеткой.

- **Байесовская оптимизация:** более умный подход. Строится модель (например, гауссовский процесс) зависимости качества от гиперпараметров по уже проверенным точкам, и новые комбинации выбираются не случайно, а там, где по прогнозу может быть лучшее качество (с учётом неопределённости). Алгоритмы типа Tree-structured Parzen Estimator (TPE), используемые в Hyperopt, Optuna, или GaussianProcess (в scikit-optimize), постепенно приближаются к оптимуму с меньшим числом запусков модели.

- **Эволюционные и другие методы:** существуют и генетические алгоритмы для подбора параметров, и метод Hyperband (комбинация случайного поиска с адаптивным выделением ресурсов, когда негодные варианты отбрасываются раньше). Эти подходы пытаются более эффективно исследовать пространство параметров, особенно если параметры много и функция оценки шумная.

- **Настройка с экспертом и поэтапно:** иногда гиперпараметры подбирают вручную, используя знание алгоритма. Например, сначала настроить самый важный параметр, потом подстроить второстепенные. Или комбинировать: провести грубый поиск по широкому диапазону (random), затем сделать более мелкую сетку вокруг лучших областей. В любом случае, используют перекрёстную валидацию или выделенную валидацию, чтобы оценить качество каждой комбинации честно.

Стратегии часто комбинируют: например, начать с random search, а затем Bayesian на лучшем интервале. Главное – автоматизировать поиск, чтобы не настраивать всё вручную, и избежать подборки под тестовую выборку (всегда держать независимый тест для финальной проверки).
