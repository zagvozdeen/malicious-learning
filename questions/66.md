---
question: Что является ключевым гиперпараметром для методов поиска аномалий в scikit-learn?
module: Практика
---

Главный гиперпараметр - это **ожидаемая доля аномалий** в данных (процент "выбросов"). Во многих алгоритмах он прямо задаётся. В sklearn для алгоритмов вроде **IsolationForest**, **LocalOutlierFactor** параметр называется contamination. Он определяет, какую часть объектов алгоритм будет считать аномалиями (например, contamination=0.05 предполагает ~5% выбросов). В **One-Class SVM** аналогичную роль играет параметр nu, который тоже примерно соответствует доле выбросов, на которую нацелен алгоритм. Этот параметр критически важен: если занизить долю, алгоритм будет слишком строгим и найдёт мало аномалий (может пропустить реальные выбросы); если завысить - пометит слишком много точек как аномальные. Поэтому настройка доли (contamination) - ключевая при поиске аномалий. Остальные параметры (например, количество деревьев в IsolationForest или гамма в One-Class SVM) тоже влияют, но без корректного задания ожидаемой доли результат будет непредсказуем: либо почти ничего не отметится выбросом, либо наоборот, слишком много "аномалий".
