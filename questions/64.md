---
question: Что нужно указать чтобы запустить процедуру отбора оптимальных гиперпараметров в scikit-learn? Какие есть тонкости при работе с Pipeline?
module: Практика
---

Чтобы начать поиск оптимальных гиперпараметров, нужно воспользоваться, например, классом **GridSearchCV** (или RandomizedSearchCV). Ему мы передаём: (1) сам estimator (модель или Pipeline), (2) словарь возможных значений гиперпараметров (param_grid), и (3) настройку кросс-валидации (например, cv=5). В словаре param_grid ключами выступают названия гиперпараметров, а значениями - списки вариантов. Если мы настраиваем **Pipeline**, то названия параметров шагов должны быть записаны в формате "имяШага_\_имяПараметра". Имя шага - это то, как мы назвали его при создании Pipeline. Например, если у нас Pipeline(\[("scaler", StandardScaler()), ("clf", RandomForestClassifier())\]), и мы хотим настраивать количество деревьев, то ключ будет "clf_\_n_estimators". Можно настраивать параметры нескольких шагов одновременно, включая шаги препроцессинга.

Тонкость: при работе с Pipeline некоторые параметры шагов могут влиять друг на друга. Например, если один из шагов - отбор признаков, количество оставляемых признаков может повлиять на оптимальные параметры модели. Поэтому важно задать такой param_grid, который предусматривает все сочетания (GridSearchCV их переберёт). Также нужно помнить, что **неиспользуемые шаги** можно "выключать" через специальные значения параметров (например, задать селектор признаков None), тогда Pipeline пропустит этот шаг - иногда это тоже входит в поиск параметров. Ещё тонкость: при именовании параметров не делать опечаток - иначе GridSearchCV не поймёт, о каком шаге речь. В целом, главное - **правильно составить словарь param_grid с названиями параметров (для Pipeline - с префиксами шагов)**, и указать подходящую стратегию поиска и число фолдов. После вызова grid_search.fit(X, y) процедура сама переберёт все указанные комбинации и выберет лучшую по оценке качества.
