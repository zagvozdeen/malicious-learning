---
question: Какие особенности применение градиентного спуска в методе визуализации t-SNE?
module: Теория
---

Алгоритм t-SNE настраивает расположение точек в низкоразмерном пространстве с помощью оптимизации специальной функции стоимости. Тут используются итерации градиентного спуска, и у этого процесса есть несколько особенностей:

- **Нестандартная целевая функция:** t-SNE минимизирует расхождение (дивергенцию Кульбака-Лейблера) между распределениями расстояний в исходном и целевом пространстве. Эта функция сложная и **не имеет единственного минимума** (не выпуклая), поэтому градиентный спуск может застревать в локальных минимальных конфигурациях в зависимости от начальной инициализации.

- **Высокая вычислительная сложность:** прямой градиентный спуск требует учитывать пары всех точек (O(n^{2}) операций) для расчёта сил притяжения/отталкивания между каждой парой. На практике для ускорения используют приближённые методы (например, алгоритм Barnes-Hut для аппроксимации дальних взаимодействий), чтобы сделать вычисления быстрее.

- **Специальные приёмы в оптимизации:** чтобы добиться хорошего результата, t-SNE применяет техники, такие как *early exaggeration* (искусственно увеличивает притяжение кластеров на первых итерациях, чтобы раздвинуть группы точек), и использует momentum (инерцию) при обновлении позиций, чтобы обходить неглубокие ловушки локальных минимумов. Шаг градиентного спуска (learning rate) тоже нужно подбирать: слишком большой – точки могут "разлететься", слишком маленький – процесс займет много времени или застрянет.

Таким образом, градиентный спуск в t-SNE – итеративная процедура, требующая аккуратной настройки. Это не простой спуск как в линейной регрессии: он оптимизирует нетривиальную функцию, занимает больше времени и зависит от параметров (перплексии, начальных условий) для получения удачной визуализации.
