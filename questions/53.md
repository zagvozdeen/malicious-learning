---
question: Почему в реализации деревьев решений от scikit-learn всё-таки стоит использовать one-hot кодирование при использовании категориальных признаков (ну или Target Encoder)?
module: Практика
---

В scikit-learn дерево решений **не умеет напрямую работать с категориальными признаками** - все входные данные должны быть числовыми. Если просто закодировать категории каким-то числом (например, красный=1, зелёный=2, синий=3), то дерево воспримет эти значения как имеющие порядок и расстояния (будет делить по условию типа "<=2" и т.д.), хотя у категорий такого естественного порядка нет. Это может привести к нелогичным разбиениям (например, объединит красный и зелёный против синего только потому, что 1 и 2 меньше 3). Поэтому рекомендуется применять **one-hot кодирование**: каждая категория превращается в отдельный бинарный признак (0 или 1). Дерево тогда самостоятельно решит, какой из этих индикаторов использовать в разбиении, и не будет делать ошибочных выводов о "больше/меньше" между разными категориями.

Допустим также **target encoding** (кодирование категории средним значением целевой переменной) - его иногда используют, особенно в задачах с большим числом категорий. Target encoding тоже даёт числовое представление категории, но уже основанное на влиянии на целевую переменную. Однако с ним надо быть осторожным, чтобы не допустить утечки информации о целевой переменной. В целом же, one-hot - более надёжный и простой способ, поэтому его и предпочитают для деревьев решений.
